{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing performance of intent classification in Watson Conversation Service\n",
    "[Watson Developer Cloud](https://www.ibm.com/watsondevelopercloud) is a platform of cognitive services that leverage machine learning techniques to help partners and clients solve a variety business problems. Furthermore, several of the WDC services fall under the **supervised learning** suite of machine learning algorithms, that is, algorithms that learn by example. This begs the questions: \"How many examples should we provide?\" and \"When is my solution ready for prime time?\"\n",
    "\n",
    "It is critical to understand that training a machine learning solution is an iterative process where it is important to continually improve the solution by providing new examples and measuring the performance of the trained solution. In this notebook, we show how you can compute important Machine Learning metrics (accuracy, precision, recall, confusion_matrix) to judge the performance of your Watson Conversation service solution. For more details on these various metrics, please consult the **[Is Your Chatbot Ready for Prime-Time?](https://developer.ibm.com/dwblog/2016/chatbot-cognitive-performance-metrics-accuracy-precision-recall-confusion-matrix/)** blog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The notebook assumes you have already created a [Watson Conversation Service](https://www.ibm.com/watson/developercloud/conversation.html) instance and trained it based on a number of intents. </br>\n",
    "<br> To leverage this notebook, you need to provide the following information</br>\n",
    "* Credentials for your Watson Conversation instance (username and password)\n",
    "* Workspace id for your conversation \n",
    "* csv file with your text utterances and corresponding intent labels\n",
    "* results csv file to write the results to\n",
    "* csv file to write confusion matrix results to\n",
    "\n",
    "Note that the input test csv file should have a header with the fields **text** and **class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import utilities\n",
    "import json\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ml\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from watson_developer_cloud import ConversationV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path to the parms file which includes credentials to access your Conversation service as well as the input\n",
    "test csv file and the output csv files to write the output results and confusion matrix to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide complete path to the file which includes all required parms\n",
    "# A sample parms file is included (example_parms.json)\n",
    "convParmsFile = 'PATH to CONVERSATION parms file'\n",
    "parms = ''\n",
    "with open(convParmsFile) as parmFile:\n",
    "    parms = json.load(parmFile)\n",
    "\n",
    "url=parms['url']\n",
    "user=parms['user']\n",
    "password=parms['password']\n",
    "workspace_id=parms['workspace_id']\n",
    "test_csv_file=parms['test_csv_file']\n",
    "results_csv_file=parms['results_csv_file']\n",
    "confmatrix_csv_file=parms['confmatrix_csv_file']\n",
    "\n",
    "# Create an object for your Conversation instance\n",
    "conversation = ConversationV1(\n",
    "  username=user,\n",
    "  password=password,\n",
    "  version='2017-02-03')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define useful methods to classify using trained Watson Conversation service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a text string and a pointer to Conversation instance and workspaceID, get back Conversation response\n",
    "def getConversationResponse(conv_instance,workspaceID,string):\n",
    "    context={}\n",
    "    response = conv_instance.message(\n",
    "        workspace_id=workspaceID, \n",
    "        message_input={'text':string},\n",
    "        context=context)\n",
    "    classes=response\n",
    "    return classes\n",
    "\n",
    "# Process multiple text utterances (provided via csv file) in batch. Effectively, read the csv file and for each text\n",
    "# utterance, get NLC response. Aggregate and return results.\n",
    "def batchConversation(conv_instance,workspaceID,csvfile):\n",
    "    test_classes=[]\n",
    "    convpredict_classes=[]\n",
    "    convpredict_confidence=[]\n",
    "    text=[]\n",
    "    i=0\n",
    "    with open(csvfile) as csvfile:\n",
    "        csvReader=csv.DictReader(csvfile)\n",
    "        print('csvfile: ', csvfile)\n",
    "        for row in csvReader:\n",
    "            print ('testing row: ', row['text'])\n",
    "            test_classes.append(row['class'])\n",
    "            conv_response = getConversationResponse(conv_instance,workspaceID,row['text'])\n",
    "            #print 'response: ', conv_response\n",
    "            if conv_response['intents']: \n",
    "                convpredict_classes.append(conv_response['intents'][0]['intent'])\n",
    "                convpredict_confidence.append(conv_response['intents'][0]['confidence'])\n",
    "            else:\n",
    "                convpredict_classes.append('')\n",
    "                convpredict_confidence.append(0)\n",
    "            text.append(row['text'])\n",
    "            i = i+1\n",
    "            if(i%250 == 0):\n",
    "                print ('Processed ', i, ' records')\n",
    "        print ('Finished processing ', i, ' records')\n",
    "    return test_classes, convpredict_classes, convpredict_confidence, text\n",
    "\n",
    "# Plot confusion matrix as an image\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    plt.figure()\n",
    "    plt.imshow(conf_matrix)\n",
    "    plt.show()\n",
    "\n",
    "# Print confusion matrix to a csv file\n",
    "def confmatrix2csv(conf_matrix,labels,csvfile):\n",
    "    with open(csvfile, 'w') as csvfile:\n",
    "        csvWriter = csv.writer(csvfile)\n",
    "        row=list(labels)\n",
    "        row.insert(0,\"\")\n",
    "        csvWriter.writerow(row)\n",
    "        for i in range(conf_matrix.shape[0]):\n",
    "            row=list(conf_matrix[i])\n",
    "            row.insert(0,labels[i])\n",
    "            csvWriter.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an optional step to quickly test response from NLC for a given utterance\n",
    "#testQ='I have a billing question'\n",
    "#results = getConversationResponse(conversation,workspace_id,testQ)\n",
    "#print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Conversation on the specified csv file and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classes,convpredict_classes,convpredict_conf,text=batchConversation(conversation,workspace_id,test_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results to csv file including original text, the correct label, \n",
    "# the predicted label and the confidence reported by Conversation.\n",
    "csvfileOut=results_csv_file\n",
    "with open(csvfileOut,'w') as csvOut:\n",
    "    outrow=['text','true class','Conversation Predicted class','Confidence']\n",
    "    csvWriter = csv.writer(csvOut,dialect='excel')\n",
    "    csvWriter.writerow(outrow)\n",
    "    for i in range(len(text)):\n",
    "        outrow=[text[i],test_classes[i],convpredict_classes[i],str(convpredict_conf[i])]\n",
    "        csvWriter.writerow(outrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "labels=list(set(test_classes))\n",
    "conv_confusion_matrix = confusion_matrix(test_classes, convpredict_classes, labels)\n",
    "convConfMatrix = ConfusionMatrix(test_classes, convpredict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out confusion matrix with labels to csv file\n",
    "confmatrix2csv(conv_confusion_matrix,labels,confmatrix_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "convConfMatrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute accuracy of classification\n",
    "acc=accuracy_score(test_classes, convpredict_classes)\n",
    "print ('Classification Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print precision, recall and f1-scores for the different classes\n",
    "print(classification_report(test_classes, convpredict_classes, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional if you would like each of these metrics separately\n",
    "#[precision,recall,fscore,support]=precision_recall_fscore_support(test_classes, convpredict_classes, labels=labels)\n",
    "#print ('precision: ', precision)\n",
    "#print ('recall: ', recall)\n",
    "#print ('f1 score: ', fscore)\n",
    "#print ('support: ', support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
