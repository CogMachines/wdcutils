{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Notebook for testing performance of NLC classification\n",
    "[Watson Developer Cloud](https://www.ibm.com/watsondevelopercloud) is a platform of cognitive services that leverage machine learning techniques to help partners and clients solve a variety business problems. Furthermore, several of the WDC services fall under the **supervised learning** suite of machine learning algorithms, that is, algorithms that learn by example. This begs the questions: \"How many examples should we provide?\" and \"When is my solution ready for prime time?\"\n",
    "\n",
    "It is critical to understand that training a machine learning solution is an iterative process where it is important to continually improve the solution by providing new examples and measuring the performance of the trained solution. In this notebook, we show how you can compute important Machine Learning metrics (accuracy, precision, recall, confusion_matrix) to judge the performance of your solution. For more details on these various metrics, please consult the **[Is Your Chatbot Ready for Prime-Time?](https://developer.ibm.com/dwblog/2016/chatbot-cognitive-performance-metrics-accuracy-precision-recall-confusion-matrix/)** blog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The notebook assumes you have already created a Watson [Natural Language Classifier](https://www.ibm.com/watson/developercloud/nl-classifier.html) instance and trained a classifier. </br>\n",
    "<br> To leverage this notebook, you need to provide the following information</br>\n",
    "* Credentials for your NLC instance (username and password)\n",
    "* id for your trained classifier (this is returned when you train an NLC classifier)\n",
    "* csv file with your text utterances and corresponding class labels\n",
    "* results csv file to write the results to\n",
    "\n",
    "Note that the input test csv file should have a header with the fields **text** and **class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import utilities\n",
    "import json\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ml\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from watson_developer_cloud import NaturalLanguageClassifierV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the path to the parms file which includes credentials to access your NLC service as well as the input\n",
    "test csv file and the output csv file to write the output results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide complete path to the file which includes all required parms\n",
    "# A sample parms file is included (example_parms.json)\n",
    "nlcParmsFile = 'PATH to your PARMS file'\n",
    "parms = ''\n",
    "with open(nlcParmsFile) as parmFile:\n",
    "    parms = json.load(parmFile)\n",
    "\n",
    "url=parms['url']\n",
    "user=parms['user']\n",
    "password=parms['password']\n",
    "nlc_id=parms['nlc_id']\n",
    "test_csv_file=parms['test_csv_file']\n",
    "results_csv_file=parms['results_csv_file']\n",
    "confmatrix_csv_file=parms['confmatrix_csv_file']\n",
    "\n",
    "json.dumps(parms)\n",
    "\n",
    "# Create an object for your NLC instance\n",
    "natural_language_classifier = NaturalLanguageClassifierV1(\n",
    "  username=user,\n",
    "  password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define useful methods to classify using trained NLC classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a text string and a pointer to NLC instance and classifierID, get back NLC response\n",
    "def getNLCresponse(nlc_instance,classifierID,string):\n",
    "    classes = nlc_instance.classify(classifierID, string)\n",
    "    return classes\n",
    "\n",
    "# Process multiple text utterances (provided via csv file) in batch. Effectively, read the csv file and for each text\n",
    "# utterance, get NLC response. Aggregate and return results.\n",
    "def batchNLC(nlc_instance,classifierID,csvfile):\n",
    "    test_classes=[]\n",
    "    nlcpredict_classes=[]\n",
    "    nlcpredict_confidence=[]\n",
    "    text=[]\n",
    "    i=0\n",
    "    with open(csvfile, 'r') as csvfile:\n",
    "        csvReader=csv.DictReader(csvfile)\n",
    "        for row in csvReader:\n",
    "            test_classes.append(row['class'])\n",
    "            nlc_response = getNLCresponse(nlc_instance,classifierID,row['text'])\n",
    "            nlcpredict_classes.append(nlc_response['classes'][0]['class_name'])\n",
    "            nlcpredict_confidence.append(nlc_response['classes'][0]['confidence'])\n",
    "            text.append(row['text'])\n",
    "            i = i+1\n",
    "            if(i%250 == 0):\n",
    "                print ('Processed ', i, ' records')\n",
    "        print ('Finished processing ', i, ' records')        \n",
    "    return test_classes, nlcpredict_classes, nlcpredict_confidence, text\n",
    "\n",
    "# Plot confusion matrix as an image\n",
    "def plot_conf_matrix(conf_matrix):\n",
    "    plt.figure()\n",
    "    plt.imshow(conf_matrix)\n",
    "    plt.show()\n",
    "\n",
    "# Print confusion matrix to a csv file\n",
    "def confmatrix2csv(conf_matrix,labels,csvfile):\n",
    "    with open(csvfile, 'w') as csvfile:\n",
    "        csvWriter = csv.writer(csvfile)\n",
    "        row=list(labels)\n",
    "        row.insert(0,\"\")\n",
    "        csvWriter.writerow(row)\n",
    "        for i in range(conf_matrix.shape[0]):\n",
    "            row=list(conf_matrix[i])\n",
    "            row.insert(0,labels[i])\n",
    "            csvWriter.writerow(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an optional step to quickly test response from NLC for a given utterance\n",
    "#testQ='can I reset my password'\n",
    "#results = getNLCresponse(natural_language_classifier,nlc_id,testQ)\n",
    "#print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call NLC on the specified csv file and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes,nlcpredict_classes,nlcpredict_conf,text=batchNLC(natural_language_classifier,nlc_id,test_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results to csv file including original text, the correct label, \n",
    "# the predicted label and the confidence reported by NLC.\n",
    "csvfileOut=results_csv_file\n",
    "with open(csvfileOut, 'w') as csvOut:\n",
    "    outrow=['text','true class','NLC Predicted class','Confidence']\n",
    "    csvWriter = csv.writer(csvOut,dialect='excel')\n",
    "    csvWriter.writerow(outrow)\n",
    "    for i in range(len(text)):\n",
    "        outrow=[text[i],test_classes[i],nlcpredict_classes[i],str(nlcpredict_conf[i])]\n",
    "        csvWriter.writerow(outrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "labels=list(set(test_classes))\n",
    "nlc_confusion_matrix = confusion_matrix(test_classes, nlcpredict_classes, labels)\n",
    "nlcConfMatrix = ConfusionMatrix(test_classes, nlcpredict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out confusion matrix with labels to csv file\n",
    "confmatrix2csv(nlc_confusion_matrix,labels,confmatrix_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nlcConfMatrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of classification\n",
    "acc=accuracy_score(test_classes, nlcpredict_classes)\n",
    "print ('Classification Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print precision, recall and f1-scores for the different classes\n",
    "print(classification_report(test_classes, nlcpredict_classes, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optional if you would like each of these metrics separately\n",
    "#[precision,recall,fscore,support]=precision_recall_fscore_support(test_classes, nlcpredict_classes, labels=labels)\n",
    "#print ('precision: ', precision)\n",
    "#print ('recall: ', recall)\n",
    "#print ('f1 score: ', fscore)\n",
    "#print ('support: ', support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
